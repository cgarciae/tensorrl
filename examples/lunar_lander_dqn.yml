memory-limit: 100000
target-model-update: 0.01
gamma: 0.999
warmup-steps: 10000
batch-size: 512
summary-steps: 100
save-steps: 10000
max-steps: 1000000
learning-rate: 0.001
seed: 123
train_cycles: 1
huber_dalta: 400.0
# regularization: 0.0001